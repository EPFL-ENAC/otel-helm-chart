nameOverride: ""
fullnameOverride: ""

global:
  imagePullSecrets: []

collector:
  image:
    repository: otel/opentelemetry-collector-contrib
    tag: 0.95.0

  serviceAccount:
  
  exporters:
    port: 9464
    portName: metrics
    path: /metrics
    scheme: http
    interval: 30s

  receivers:
    grpc:
      port: 4317
    http:
      port: 4318

  config:
    # If you provide receivers, processors, exporters or service configuration,
    # it will be used instead of the default one. You can use this to customize
    # the collector configuration beyond what is supported by the default values.

    receivers:
    #   otlp:
    #     protocols:
    #       grpc:
    #        endpoint: 0.0.0.0:{{ .Values.collector.receivers.grpc.port }}
    #      http:
    #        endpoint: 0.0.0.0:{{ .Values.collector.receivers.http.port }}

    processors:
    #   filter:
    #     metrics:
    #       datapoint:
    #         - 'attributes["http.target"] == "/api/health"'

    exporters:
    #   prometheus:
    #     endpoint: 0.0.0.0:{{ .Values.collector.exporters.port }}
    #     resource_to_telemetry_conversion:
    #       enabled: true

    service:
    #   pipelines:
    #     metrics:
    #       receivers: [otlp]
    #       processors: [filter]
    #       exporters: [prometheus]

  metrics:
    # enabled: true
    grafanaMonitor:
      enabled: true

  resources:
    limits:
      memory: "256Mi"
    requests:
      cpu: "10m"
      memory: "256Mi"

jaeger:
  enabled: true
  image:
    repository: jaegertracing/all-in-one
    tag: "1.49"
  
  # jaeger.memoryMaxTraces
  # Maximum number of traces that can be stored in memory. Once the limit is reached, new traces will be dropped until some of the existing traces are flushed to the storage backend. Setting this value to 0 means no limit.
  memoryMaxTraces: 100000

  endpoints:
    grpc:
      port: 4317
    http:
      port: 16686

  resources:
    limits:
      memory: "512Mi"
    requests:
      cpu: "10m"
      memory: "512Mi"
